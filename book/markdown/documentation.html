<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Mémoire digitale: les enjeux de l’archive numérique et du Big Data" href="memoire.html" /><link rel="prev" title="&lt;no title&gt;" href="../../index.html" />

    <!-- Generated with Sphinx 5.0.2 and Furo 2023.03.27 -->
        <title>Les enjeux dans le développement d’un jeu de données autour des fonds numérisés de la Bibliothèque Nationale de France - Intership CESR 23</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/vue/fonts.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Intership CESR 23</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/logo-gallica.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Intership CESR 23</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Rapport et mémoire</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Les enjeux dans le développement d’un jeu de données autour des fonds numérisés de la Bibliothèque Nationale de France</a></li>
<li class="toctree-l1"><a class="reference internal" href="memoire.html">Mémoire digitale: les enjeux de l’archive numérique et du Big Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/pipeline.html">Pipeline de collecte des données</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/labelstudio.html">Guide de pratique pour Label Studio</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Références</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section class="tex2jax_ignore mathjax_ignore" id="les-enjeux-dans-le-developpement-d-un-jeu-de-donnees-autour-des-fonds-numerises-de-la-bibliotheque-nationale-de-france">
<h1>Les enjeux dans le développement d’un jeu de données autour des fonds numérisés de la Bibliothèque Nationale de France<a class="headerlink" href="#les-enjeux-dans-le-developpement-d-un-jeu-de-donnees-autour-des-fonds-numerises-de-la-bibliotheque-nationale-de-france" title="Permalink to this heading">#</a></h1>
<section id="contextualisation">
<h2>Contextualisation<a class="headerlink" href="#contextualisation" title="Permalink to this heading">#</a></h2>
<p>Dans le cadre de l’appel à projet émis par la Bibliothèque Nationale de France (<em>BnF</em>) et s’inscrivant dans le projet <a class="reference external" href="https://www.economie.gouv.fr/france-2030">France Relance 2030</a>, il est demandé aux prestataires de mettre en place une solution de fouille d’images autour des documents présents sur <a class="reference external" href="https://gallica.bnf.fr/">Gallica Images</a>. Aujourd’hui il est possible d’indexer des images sur Gallica Images grâce aux métadonnées qui leur sont associées. Ces métadonnées sont issues des archives dont elles proviennent, elles sont donc purement descriptives. Chaque métadonnée concerne un document et ce document peut être associé à plusieurs images. Dans le cas, par exemple, d’une collection de photographies sur pellicule, l’ensemble des images partagent la même métadonnée, ce qui nous donne des informations sur l’ensemble de collection mais pas à l’échelle des images.
Tout l’enjeu de cet appel à projet est d’incorporer des briques d’intelligence artificielle à l’infrastructure déjà préexistante afin de développer une nouvelle chaîne de traitement automatique des documents, basée sur une approche de segmentations et de classifications. L’objectif est d’extraire de nouvelles métadonnées pour l’image en complément de celle déjà présente, afin de permettre une meilleure exposition des documents, leurs croisement et la fouille d’images.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="../../_images/research-gallica.png"><img alt="../../_images/research-gallica.png" src="../../_images/research-gallica.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Recherche avancée aujourd’hui sur <a class="reference external" href="https://gallica.bnf.fr/services/engine/search/advancedSearch/">Gallica Images</a></span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><em>Il est à noté que le prestaire est libre de proposer les technologies qui lui semble en adéquation avec l’enjeux exposé précédemment.</em></p>
</div>
<p>Mon stage s’inscrit dans la phase de sélection des prestataires. Pour évaluer les modèles des différents prestataires, il est essentiel de faire un inventaire le plus factuel possible des données qu’ils devront automatiser, notamment à des fins d’évaluation autour d’un ensemble de mesures de la qualité. Cet inventaire et ces mesures de qualité prendront la forme d’un jeu de données, qui se voudra représentatif sur le nombre et le type de documents présents sur Gallica Images.</p>
<p>L’organisation du marché est découpé de la façon suivante :</p>
<ol class="arabic simple">
<li><p><strong>Tranche ferme</strong> : Développement, paramétrage et mise en place d’une version initiale du système d’identification et d’indexation des illustrations, initialisation sur la collection Images (estampes, dessins et photographies, <em>1.4 millions de pages</em> environ) dont une prestation de livraison.</p></li>
<li><p><strong>Tranche optionnelle 1</strong> : Développement complémentaire - Monographies imprimées avec traitements associés d’un échantillon de tests de <em>20 000 pages</em> de la collection dont une prestation de livraison.</p></li>
<li><p><strong>Tranche optionnelle 2</strong> : Développement complémentaire - Périodiques avec traitements associés d’un échantillon de test de <em>20 000 pages</em> de la collection dont une prestation de livraison.</p></li>
<li><p><strong>Tranche optionnelle 3</strong> : Développement complémentaire - Manuscrit avec traitements associés d’un échantillon de tests de <em>20 000 pages</em> de la collection dont une prestation de livraison.</p></li>
<li><p><strong>Tranche optionnelle 4</strong> : Développement complémentaire - Documents spécialisés (partition musicales, cartes et plans, monnaies) avec traitements associés d’un échantillon de tests de <em>20 000 pages</em> de la collection dont une prestation de livraison</p></li>
</ol>
<p>Ce premier jeu de données s’articulera donc avec la tranche ferme, autour de trois types de documents : <strong>les estampes, le dessin et la photographie</strong>.</p>
</section>
<section id="creation-du-jeu-de-donnee">
<h2>Création du jeu de donnée<a class="headerlink" href="#creation-du-jeu-de-donnee" title="Permalink to this heading">#</a></h2>
<p>Comme évoqué précédemment, la création d’un jeu de données permettra à la BnF de mettre à disposition un ensemble de documents ainsi que leurs métadonnées aux différents prestataires. Afin qu’ils puissent évaluer conjointement la qualité des modèles de segmentations et de classifications. Le jeu de données mettra à disposition deux grands types de données.</p>
<ul class="simple">
<li><p>Des données structurées et riches sémantiquement à travers les métadonnées associées à chaque document :</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Vallée du Gave - Vue prise du Parc à Pau / J. A.&#39;</span><span class="p">],</span> 
<span class="s1">&#39;creator&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;J. A.. Fonction indéterminée&#39;</span><span class="p">],</span> 
<span class="s1">&#39;subject&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Photographie stéréoscopique -- 19e siècle&#39;</span><span class="p">,</span> <span class="s1">&#39;Gave de Pau, Vallée du (France) -- 19e siècle -- Photographies&#39;</span><span class="p">],</span> 
<span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Appartient à l’ensemble documentaire : PrnS001&#39;</span><span class="p">],</span> 
<span class="s1">&#39;relation&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Notice du catalogue : http://catalogue.bnf.fr/ark:/12148/cb449506875&#39;</span><span class="p">],</span> 
<span class="s1">&#39;identifier&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;http://gallica.bnf.fr/ark:/12148/btv1b10584517b&#39;</span><span class="p">],</span> <span class="s1">&#39;rights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;domaine public&#39;</span><span class="p">],</span> 
<span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;image fixe&#39;</span><span class="p">,</span> <span class="s1">&#39;photographie&#39;</span><span class="p">],</span> 
<span class="s1">&#39;language&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Sans contenu linguistique&#39;</span><span class="p">],</span> 
<span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;18??&#39;</span><span class="p">],</span> 
<span class="s1">&#39;format&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;photographie stéréoscopique, 16,8 x 8,5 cm&#39;</span><span class="p">,</span> <span class="s1">&#39;image/jpeg&#39;</span><span class="p">,</span> <span class="s1">&#39;Nombre total de vues :  1&#39;</span><span class="p">],</span> <span class="s1">&#39;source&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Archives et bibliothèques Pau Béarn Pyrénées, PHA152 (469)&#39;</span><span class="p">]}</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p>Des données semi-structurées et faibles sémantiquement à travers l’image car, au-delà de la structure de celle-ci (hauteur, largeur, nombre de canaux (couleurs, noir et blanc)), il est difficile d’obtenir des informations sémantiques pertinentes sans l’aide d’un modèle d’apprentissage automatique.</p></li>
</ul>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="../../_images/btv1b105845b.jpeg"><img alt="../../_images/btv1b105845b.jpeg" src="../../_images/btv1b105845b.jpeg" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Exemple de donnée semi-structurée et faible sémantiquement
btv1b10584517b | Vallée du Gave - Vue prise du Parc à Pau / J. A | Archives et bibliothèques Pau Béarn Pyrénées</span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<hr class="docutils" />
<p>La classification et l’extraction d’informations s’effectueront donc à travers ces deux types de données qui pourront s’entre alimenter une fois la collection moissonnée. C’est-à-dire classifier de futur document ne présentant aucune métadonnée ou bien entre-croiser la recherche de documents suite à la segmentation et classification des images. Le prestataire disposant d’une liberté dans le choix des technologies et des modèles d’apprentissage automatique choisit, il est évident que certaines métriques seront amenées à être développées lors de la phase de sélection.</p>
<p>En revanche, nous devons  procéder à une analyse la plus fine possible sur les documents et les métadonnées présents dans Gallica Images (notamment les estampes, photographies, et dessins). Garantir une population représentative, afin d’amoindrir les biais qui se traduirait par des erreurs de classification, et de favoriser la généralisation des modèles qui se traduirait par la capacité d’extrapoler les résultats d’un échantillon de population sur son ensemble.</p>
</section>
<section id="acquisition-et-analyse-des-donnees">
<h2>Acquisition et analyse des données<a class="headerlink" href="#acquisition-et-analyse-des-donnees" title="Permalink to this heading">#</a></h2>
<p>Le service Gallica dispose de divers protocoles qui permettent l’exploitation et l’extraction de leurs ressources numériques. Une <a class="reference external" href="https://fr.wikipedia.org/wiki/Interface_de_programmation">API</a> (Application Programming Interface) non standardisée et un protocole <a class="reference external" href="https://www.bnf.fr/fr/protocole-oai-pmh">OAI-PMH</a> (Open Archives Initiative - Protocol for Metadata Harvesting) qui permet de récupérer les métadonnées des documents (donc d’images) présentes sur Gallica Images
Afin de contextualiser la procédure de téléversement de ces métadonnées, il est important de rappeler qu’à travers le protocole OAI-PMH, la Bibliothèque Nationale de France offre la possibilité à d’autre partenaires de téléverser leurs données à des fins de préservation et de mise à disposition de leurs infrastructures. En effet, certaines institutions ne possèdent pas les équipements nécessaires pour numériser leurs documents, ni les ressources infrastructurelles pour héberger leurs documents et faire face au trafic que cela générerait. Cette initiative prend la forme du concept « marque blanche ».</p>
<p>Les documents présents dans l’entrepôt sont donc issus de sources éparses qui s’accompagnent de différentes échelles de granularité. La Bibliothèque Nationale de France met à disposition un <a class="reference external" href="https://multimedia-ext.bnf.fr/pdf/Guide_oaipmh.pdf">Guide d’interopérabilité OAI-PMH</a> pour un référencement des documents numériques dans Gallica pour que les institutions qui décident de téléverser leurs ressources calquent leurs métadonnées sur ce référentiel. Dans la pratique cela fonctionne, mais la plupart du temps les métadonnées ne sont pas corrélées entre les différentes institutions. Il est donc parfois difficile d’analyser de façon formelle certains documents par le fait que les métadonnées sont mal formatées ou non renseignées.
Il a donc fallu collecter dans l’entrepôt OAINUM, l’ensemble des métadonnées qui traitent de document relatif aux dessins, estampes, photographies afin d’effectuer leurs exploration et analyses. Pour créer une population représentative, nous nous sommes penchés sur les caractéristiques suivantes:</p>
<ol class="arabic simple">
<li><p>Indication sur le type de document</p></li>
<li><p>Indication sur la techniques du document</p></li>
<li><p>Indication sur la fonction du document</p></li>
<li><p>Indication sur la date du document</p></li>
<li><p>Indication sur la colorimétrie du document</p></li>
<li><p>Indication sur la présente de texte</p></li>
<li><p>Indication sur le nombre de vues</p></li>
</ol>
<p>Après l’analyse et l’exploration de ces caractéristiques, plusieurs constat sont établis. Premièrement, il est difficile d’obtenir des informations pertinentes pour l’ensemble de la population notamment car ces indications étaient majoritairement absentes. Deuxièmement, l’application de listes d’autorités et de manipulations des informations soulève une question de véracité de l’information qui en a été extraite car elle n’a pas été réalisée conjointement avec des experts du domaine. Et pour finir, on observe un effet de sédimentation qui s’applique par la temporalité des informations qui ont été télévisées. Sur des mêmes périodes on observe beaucoup d’erreurs de formatage communes, qui s’accompagnent parfois par un changement de granularité, notamment à travers différents référentiels qui sont actualisés ou mis à jour sans réactualisation des anciennes métadonnées.</p>
<p>Lors de la fouille et l’analyse des métadonnées, les projections ont été réalisées sur un jeu de données comportant <strong>30 000 documents</strong> (et non d’images) par rapport à une population totale de <strong>468 494 documents</strong>.</p>
<p>Nous retrouvons majoritairement des types de documents associés à la photographie qui sont environ 5 fois plus présents que les dessins et environ 2 fois plus présents que les estampes, en notant que 11.07% des documents ne sont associés à aucun type de documents. Il est également intéressant et forcé de constater que des documents peuvent être associés à plusieurs types de documents à la fois. Cela s’explique par le lien étroit qu’il existe entre ces trois types de documents : une estampe repose préalablement sur du dessin et des procédés photographiques repose parfois sur de l’estampe comme la photomécanique</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>type de document</p></th>
<th class="head"><p>pourcentage</p></th>
<th class="head"><p>nombre de documents</p></th>
<th class="head"><p>projection sur le jeu de donnée</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>dessin</p></td>
<td><p>11.67%</p></td>
<td><p>54408</p></td>
<td><p>3483</p></td>
</tr>
<tr class="row-odd"><td><p>estampe</p></td>
<td><p>23.49%</p></td>
<td><p>7047</p></td>
<td><p>7047</p></td>
</tr>
<tr class="row-even"><td><p>photographie</p></td>
<td><p>53.83%</p></td>
<td><p>252212</p></td>
<td><p>16149</p></td>
</tr>
<tr class="row-odd"><td><p>non assigné</p></td>
<td><p>11.07%</p></td>
<td><p>51837</p></td>
<td><p>3321</p></td>
</tr>
</tbody>
</table>
</div>
<p>Nous avons créé plusieurs listes d’autorités afin de récupérer des informations complémentaires concernant : les techniques, les fonctions, les dates, le nombre d’images présentes par documents. L’objectif étant de dresser des sous populations pour les estampes, les photographies et les dessins.</p>
<p>Chaque à étape de cette chaîne de traitement (de l’acquisition à l’exploration) est détaillé dans le <a class="reference internal" href="../notebooks/pipeline.html"><span class="doc std std-doc">pipeline de collecte des données</span></a></p>
</section>
<section id="etablissement-du-ground-truth">
<h2>Etablissement du <em>«ground truth»</em><a class="headerlink" href="#etablissement-du-ground-truth" title="Permalink to this heading">#</a></h2>
<p>Dans le contexte de la réalisation d’un jeu de données pour la classification et la segmentation, le «<em>ground truth</em>» fait référence aux annotations ou aux étiquettes correctes associées à chaque exemple de données. Il s’agit de la référence ou de la vérité absolue utilisée pour évaluer la performance des modèles d’apprentissage automatique.</p>
<p>Dans le cas de la classification, le ground truth indique la classe réelle à laquelle chaque exemple de données appartient. Par exemple, si vous construisez un jeu de données pour classifier des images en chats et chiens, le ground truth désignerait l’étiquette correcte (chat ou chien) pour chaque image.</p>
<p>Pour la segmentation, le ground truth consiste en une carte d’étiquetage qui définit les différentes régions ou les contours d’intérêt dans une image. Chaque pixel de l’image est étiqueté selon la classe à laquelle il appartient.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="../../_images/bbox.png"><img alt="../../_images/bbox.png" src="../../_images/bbox.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">Exemple de <em>«bouding-box»</em> présent dans le jeu de donnée</span><a class="headerlink" href="#id3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Ces deux méthodes peuvent-être jointes à travers une <em>«bouding-box»</em>. La bounding box est généralement utilisée pour localiser et encadrer les objets dans une image. Elle est définie par les coordonnées des quatre coins qui englobent l’objet d’intérêt.</p>
<p>Pour créer le <em>«ground truth»</em> d’une <em>«bouding-box»</em>, des annotateurs humains examinent l’image et dessinent manuellement une boîte englobante autour de chaque objet d’intérêt. Les coordonnées de cette boîte englobante sont enregistrées pour chaque objet étiqueté. Ces annotations servent de référence pour entraîner et évaluer les modèles de détection d’objets.</p>
<p>Le ground truth est généralement créé manuellement par des annotateurs humains ou peut être obtenu à partir de sources fiables. Les annotateurs examinent les données d’entrée et attribuent les étiquettes appropriées en se basant sur des instructions spécifiques ou des critères préétablis. L’exactitude du ground truth est essentielle pour évaluer la qualité des modèles de classification ou de segmentation, car il sert de référence pour calculer les métriques de performance telles que la précision, le rappel, le F-score, etc.</p>
<p>Il est important de noter que la création d’un ground truth précis et de haute qualité peut être un processus complexe et sujet à des erreurs. Par conséquent, il est souvent recommandé d’avoir plusieurs annotateurs pour évaluer et résoudre les éventuelles divergences ou incertitudes.</p>
<p>Chaque à étape dans la création du <em>«ground truth»</em> est détaillé dans le <a class="reference internal" href="../notebooks/labelstudio.html"><span class="doc std std-doc">Guide de pratique pour Label Studio</span></a></p>
</section>
<section id="definition-des-metriques">
<h2>Définition des métriques<a class="headerlink" href="#definition-des-metriques" title="Permalink to this heading">#</a></h2>
<p>Dans le cadre du jeu de données produit qui comprend des bounding boxes et des métadonnées, plusieurs métriques peuvent être utilisées pour évaluer la performance d’un modèle de détection d’objets. Voici quelques-unes des métriques couramment utilisées :</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="../../_images/metrics.png"><img alt="../../_images/metrics.png" src="../../_images/metrics.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Les différentes <em>metrics</em></span><a class="headerlink" href="#id4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ol class="arabic simple">
<li><p>Intersection over Union (IoU) : L’IoU mesure le degré de chevauchement entre la prédiction de la <em>«bouding-box»</em> et du <em>«ground truth»</em>. Il est calculé en divisant l’aire de l’intersection entre les deux boîtes par l’aire de leur union. Un IoU élevé indique une correspondance étroite entre la prédiction et le ground truth.</p></li>
<li><p>Précision (Precision) : La précision évalue la proportion des prédictions de bounding boxes correctes parmi toutes les prédictions positives effectuées par le modèle. Elle mesure la capacité du modèle à ne pas prédire de fausses détections.</p></li>
<li><p>Rappel (Recall) : Le rappel mesure la proportion des vérités terrain correctement détectées parmi toutes les instances réelles présentes dans le jeu de données. Il évalue la capacité du modèle à identifier tous les objets d’intérêt.</p></li>
<li><p>F1-score : Le F1-score est une métrique qui combine la précision et le rappel en une seule valeur. Il fournit une mesure globale de la performance du modèle en tenant compte à la fois des vrais positifs, des faux positifs et des faux négatifs.</p></li>
<li><p>Moyenne des précisions moyennes (Average Precision, AP) : L’AP est utilisée pour évaluer la précision d’un modèle de détection d’objets sur plusieurs seuils de confiance. Elle calcule la précision moyenne pour chaque seuil et les moyenne ensuite. L’AP est souvent calculée pour différents niveaux de rappel (mAP), ce qui permet d’obtenir une évaluation plus complète de la performance du modèle.</p></li>
</ol>
<p>Ces métriques sont largement utilisées dans l’évaluation des modèles de détection d’objets avec des du <em>«bounding-box»</em> et aident à quantifier la précision, le rappel et la performance globale du modèle.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/markdown"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="memoire.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Mémoire digitale: les enjeux de l’archive numérique et du Big Data</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../../index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Home</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Les enjeux dans le développement d’un jeu de données autour des fonds numérisés de la Bibliothèque Nationale de France</a><ul>
<li><a class="reference internal" href="#contextualisation">Contextualisation</a></li>
<li><a class="reference internal" href="#creation-du-jeu-de-donnee">Création du jeu de donnée</a></li>
<li><a class="reference internal" href="#acquisition-et-analyse-des-donnees">Acquisition et analyse des données</a></li>
<li><a class="reference internal" href="#etablissement-du-ground-truth">Etablissement du <em>«ground truth»</em></a></li>
<li><a class="reference internal" href="#definition-des-metriques">Définition des métriques</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    </body>
</html>